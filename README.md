# Transformer

An implementation of paper "Attention is all you need - 2017". I implemented this learning about it from different sources.

* [1. Introduction](#section1)
* [2. Import libraries](#section2)
* [3. Basic components](#section3)
  - [Create Word Embeddings](#section4)
  - [Positional Encoding](#section5)
  - [Self Attention](#section6)
* [4. Encoder](#section7)
* [5. Decoder](#section8)
* [7. Some useful resources](#section10)

Currently Under Work
